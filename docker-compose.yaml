version: "3.8"

services:
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka
    ports:
      - "9092:9092" 
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller

      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://:29092,PLAINTEXT_EXTERNAL://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data

  postgres:
    image: postgres:16
    container_name: postgres
    ports: ["5432:5432"]
    environment:
      POSTGRES_USER: debezium
      POSTGRES_PASSWORD: debezium
      POSTGRES_DB: corebank
    command: >
      -c wal_level=logical
      -c max_wal_senders=10
      -c max_replication_slots=10
      -c wal_keep_size=64
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro

  connect:
    image: quay.io/debezium/connect:2.7.3.Final
    container_name: connect
    depends_on: [kafka, postgres]
    ports: ["8083:8083"]
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      REST_ADVERTISED_HOST_NAME: connect

  txn-consumer:
    build: ./txn-consumer
    container_name: txn-consumer
    restart: always
    depends_on:
      - kafka
    environment:
      KAFKA_BROKERS: kafka:29092
      KAFKA_CLIENT_ID: txn-consumer
      KAFKA_GROUP_ID: txn-writer
      KAFKA_TOPIC: transactions
      OUTPUT_PATH: /data/transactions.log
      FROM_BEGINNING: "true"
    volumes:
      - txn_logs:/data


  txn-alert-consumer:
    build: ./txn-alert-consumer
    container_name: txn-alert-consumer
    restart: always
    depends_on:
      - kafka
    environment:
      KAFKA_BROKERS: kafka:29092
      KAFKA_CLIENT_ID: alerts-consumer
      KAFKA_GROUP_ID: alerts-reader
      KAFKA_TOPIC: alerts.duplicate_amount
      OUTPUT_PATH: /data/alert-consumer.log
      FROM_BEGINNING: "false"
    volumes:
      - txn_alertlogs:/data

  txn-api:
    build: ./txn-api
    container_name: txn-api
    depends_on:
      - postgres
    environment:
      PORT: 8080
      PGHOST: postgres
      PGPORT: 5432
      PGUSER: debezium
      PGPASSWORD: debezium
      PGDATABASE: corebank
    ports:
      - "8080:8080"


  # --- Flink cluster ---
  flink-jobmanager:
    image: flink:1.18.1-scala_2.12-java17
    container_name: flink-jobmanager
    depends_on:
      - kafka
    ports:
      - "8081:8081"   # Flink Web UI
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    command: jobmanager

  flink-taskmanager:
    image: flink:1.18.1-scala_2.12-java17
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
    command: taskmanager

  # --- Bizim job ---
  flink-job:
    build: ./job
    container_name: flink-job
    depends_on:
      - flink-jobmanager
      - flink-taskmanager
    environment:
      brokers: kafka:29092
      in: transactions
      out: alerts.duplicate_amount


volumes:
  kafka_data:
  pg_data:
  txn_logs:
  txn_alertlogs: